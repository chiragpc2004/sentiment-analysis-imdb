{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767b89e0",
   "metadata": {},
   "source": [
    "# **Sentiment Analysis on [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/data)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1621ba",
   "metadata": {},
   "source": [
    "## üöÄ **Let's Connect!**\n",
    "<p align=\"left\"> <a href=\"https://github.com/chiragpc2004\" target=\"_blank\"> <img src=\"https://img.shields.io/badge/GitHub-%23181717.svg?&style=for-the-badge&logo=github&logoColor=white\" alt=\"GitHub\"/> </a> <a href=\"https://www.linkedin.com/in/chiragpc2004/\" target=\"_blank\"> <img src=\"https://img.shields.io/badge/LinkedIn-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white\" alt=\"LinkedIn\"/> </a> <a href=\"https://mail.google.com/mail/?view=cm&fs=1&to=chiragpc2004@gmail.com\" target=\"_blank\"> <img src=\"https://img.shields.io/badge/Gmail-%23D14836.svg?&style=for-the-badge&logo=gmail&logoColor=white\" alt=\"Gmail\"/> </a> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e581c",
   "metadata": {},
   "source": [
    "## **Text Preprocessing of IMDB Movie Reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed0f7d7",
   "metadata": {},
   "source": [
    "### **Preprocessing**\n",
    "\n",
    "Before feeding the text data into machine learning models, it needs to be cleaned and transformed into a suitable format. Here are the key preprocessing steps we perform:\n",
    "\n",
    "- **Remove duplicates**: Duplicate reviews can bias the model by over-representing some data points. Removing duplicates ensures each review is unique.\n",
    "\n",
    "- **Remove HTML tags**: Sometimes the reviews contain HTML tags (like `<br>`, `<p>`, etc.) which are not useful for analysis. We use tools like BeautifulSoup to extract only the text content.\n",
    "\n",
    "- **Convert to lowercase**: Text data can have the same word in different cases (e.g., ‚ÄúGood‚Äù and ‚Äúgood‚Äù). Converting everything to lowercase makes the data uniform and helps in consistent processing.\n",
    "\n",
    "- **Remove special characters and punctuation**: Characters like `!`, `?`, `#`, or numbers may not carry useful information for sentiment analysis and can add noise. Removing them cleans the text.\n",
    "\n",
    "- **Remove stopwords**: Stopwords are common words like ‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúand‚Äù, which usually do not contribute much to the sentiment or meaning. Removing them reduces noise and focuses the model on important words.\n",
    "\n",
    "- **Lemmatization**: Words often appear in different forms (e.g., ‚Äúrunning‚Äù, ‚Äúran‚Äù, ‚Äúruns‚Äù). Lemmatization converts these variants to their base or dictionary form (e.g., ‚Äúrun‚Äù), which helps the model understand the core meaning better.\n",
    "\n",
    "- **Tokenization**: This is the process of breaking down the text into smaller units called tokens (usually words). Models work on these tokens instead of raw text.\n",
    "\n",
    "- **Vectorization**: After tokenization, the tokens need to be converted into a numerical format so they can be processed by machine learning models. This can be done using methods like:\n",
    "  - **TF-IDF** (for traditional machine learning models)\n",
    "  - **Integer encoding** (e.g., `Tokenizer.texts_to_sequences()` for deep learning models)\n",
    "\n",
    "\n",
    "- **Padding sequences**: Since reviews vary in length, sequences are padded (with zeros) to make all inputs the same length. This is important for batch processing in models like LSTMs.\n",
    "\n",
    "These preprocessing steps transform raw text reviews into a clean, consistent, and machine-readable format suitable for various machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c7637",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7988b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core and Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Text Preprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Encoding and Feature Extraction\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd2508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"D:/imdb-sentiment-classifier/data/raw/IMDB_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463c2757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the dataframe so that no errors are raised later\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cff820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews after dropping duplicates:  49582\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "print(\"Total number of reviews after dropping duplicates: \", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ddabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding sentiment column\n",
    "le = LabelEncoder()\n",
    "df['sentiment'] = le.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17336905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove html tags\n",
    "df['review'] = df['review'].apply(lambda x : BeautifulSoup(x,\"html.parser\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f91ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all reviews into lower-case\n",
    "df['review'] = df['review'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92fbc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters\n",
    "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e8185",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f57a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chira\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081115f",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abbe536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chira\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\chira\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74c5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "df['review'] = df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6422e",
   "metadata": {},
   "source": [
    "### Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c650d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/cleaned_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
